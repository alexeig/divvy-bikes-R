{"metadata":{"kernelspec":{"name":"ir","display_name":"R","language":"R"},"language_info":{"name":"R","codemirror_mode":"r","pygments_lexer":"r","mimetype":"text/x-r-source","file_extension":".r","version":"4.0.5"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/alexgerulaitis/divvy-bikes-2021-r?scriptVersionId=86182639\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"markdown","source":"# Case Study: How does a bike-share navigate speedy success?\nCapstone project by Alex Gerulaitis, as part of [Google Data Analytics Professional Certificate](https://www.coursera.org/professional-certificates/google-data-analytics) program on Coursera.\n\n**Work started**: Nov 28, 2021.\n\n**Dataset**: [Cyclistic Bike Share Dataset (Nov 2020 - Oct 2021)](https://www.kaggle.com/hassanamiri/cyclistic-bike-share-dataset-nov-2020-oct-2021)","metadata":{}},{"cell_type":"markdown","source":"<a id=\"Background\"></a>\n#### Background\n\nThe \"Case Study 1\" of the Capstone Project asks to analyze the data from a fictional bike sharing service called \"Cyclistic\", with the data supplied by a real world bike sharing service \"Divvy Bikes\". \"Cyclistic\" and \"Divvy Bikes\" will be used interchangeably in this analysis, referring to the same data. Per the Case Study:\n\n> You are a junior data analyst working in the marketing analyst team at Cyclistic, a bike-share company in Chicago. The director of marketing believes the company’s future success depends on maximizing the number of annual memberships. Therefore, your team wants to understand how casual riders and annual members use Cyclistic bikes differently. From these insights, your team will design a new marketing strategy to convert casual riders into annual members. But first, Cyclistic executives must approve your recommendations, so they must be backed up with compelling data insights and professional data visualizations.\n> \n> **Ask**\n> \n> Three questions will guide the future marketing program:\n> * How do annual members and casual riders use Cyclistic bikes differently?\n> * Why would casual riders buy Cyclistic annual memberships?\n> * How can Cyclistic use digital media to influence casual riders to become members?\n>\n> Moreno has assigned you the first question to answer: How do annual members and casual riders use Cyclistic bikes differently?\n> \n> You will produce a report with the following deliverables:\n> * A clear statement of the business task\n> * A description of all data sources used\n> * Documentation of any cleaning or manipulation of data\n> * A summary of your analysis\n> * Supporting visualizations and key findings\n> * Your top three recommendations based on your analysis","metadata":{}},{"cell_type":"markdown","source":"<a id=\"Business Task\"></a>\n#### Business Task\n\nOur task therefore is to answer the question below via deliverables outlined above:\n\n> How do annual members and casual riders use Cyclistic bikes differently?\n\n\n#### Data Sources\n\n* Dataset: [Cyclistic Bike Share Dataset (Nov 2020 - Oct 2021)](https://www.kaggle.com/hassanamiri/cyclistic-bike-share-dataset-nov-2020-oct-2021). The dataset consists of a series of CSV files that a fellow Kaggle user [Hassan Amiri](https://www.kaggle.com/hassanamiri) downloaded from Divvy Bikes public repository and uploaded to Kaggle as a public dataset (thank you!).\n* Source: [Divvy Data](https://ride.divvybikes.com/system-data): \"Historical trip data available to the public\"\n* License: [Divvy Data License Agreement](https://ride.divvybikes.com/data-license-agreement):\n> a non-exclusive, royalty-free, limited, perpetual license to access, reproduce, analyze, copy, modify, distribute in your product or service and use the Data for any lawful purpose (“License”)\n\nFor further deliverables, please follow this document.","metadata":{}},{"cell_type":"markdown","source":"<a id=\"The Process\"></a>\n### The Process\n\nWe will split the analysis into the following steps:\n\n1. Ingest Data (read from CSV file(s))\n    + Analyzie for consistency across separate CSV files.\n    + Normalize if needed (e.g. if column names, formatting or types are different between files)\n    + Combine separate CSV files into a single dataset.\n1. Clean and prepare:\n    + ID and remove aberrant data;\n    + convert types if needed (e.g. timestamps - from `character` to `POSIXct`)\n    + add data if needed (e.g. separate fields for \"day of week\", \"year\", etc.)\n1. Conduct Descriptive Analysis: identify trends and insights via statistical analysis and visualizations.\n1. Summary, conclusions, recommendations.\n\n","metadata":{}},{"cell_type":"markdown","source":"#### References\n\n* Coursera Capstone Project: [Case Study: How does a bike-share navigate speedy success?](https://www.coursera.org/learn/google-data-analytics-capstone/supplement/7PGIT/case-study-1-how-does-a-bike-share-navigate-speedy-success)\n* Kevin Hartman's [\"Divvy Exercise R Script\"](https://docs.google.com/document/d/1TTj5KNKf4BWvEORGm10oNbpwTRk1hamsWJGj6qRWpuI/edit).\n* Kevin Hartman's [\"‘Sophisticated, Clear, and Polished’: Divvy and Data Visualization (Case Study)\"](https://artscience.blog/home/divvy-dataviz-case-study).\n* [Divvy Data](https://ride.divvybikes.com/system-data): \"Historical trip data available to the public\"\n","metadata":{}},{"cell_type":"markdown","source":"### Step 1: Ingest Data","metadata":{}},{"cell_type":"markdown","source":"1.1. Initialize needed packages\n> Kaggle R environment comes with many analytics packages already installed.\n> It is defined by the [kaggle/rstats Docker image](https://github.com/kaggle/docker-rstats)","metadata":{}},{"cell_type":"code","source":"library(tidyverse) # metapackage of all tidyverse packages\nlibrary(lubridate)\nlibrary(dplyr)\nlibrary(readr)","metadata":{"execution":{"iopub.status.busy":"2022-01-26T03:00:13.961921Z","iopub.execute_input":"2022-01-26T03:00:13.964141Z","iopub.status.idle":"2022-01-26T03:00:13.989351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"1.2 Get a list of CSV files from the source data directory","metadata":{}},{"cell_type":"code","source":"# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nsource_data_dir <- \"../input/cyclistic-bike-share-dataset-nov-2020-oct-2021/\"\n# list.files(path = source_data_dir)\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\ncsv_file_list <- list.files( path=source_data_dir, pattern=\"^.+\\\\.csv$\", full.names = FALSE, include.dirs = FALSE)","metadata":{"execution":{"iopub.status.busy":"2022-01-26T03:00:13.992637Z","iopub.execute_input":"2022-01-26T03:00:13.994569Z","iopub.status.idle":"2022-01-26T03:00:14.019521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"1.3. Read the CSV files into a Dataframe while also:\n* compute `ride_duration_sec` field for the ride duration in seconds and add it to the dataframe\n* create small `colnames_df` and `metadata_df` dataframes that will assist us in confirming uniformity of column names in the CSV files (not a given) and normalizing the data\n* drops columns that are not needed: longitude, latitude, etc. (These might be helpful potentially in restoring missing data such as missing stations names and IDs - yet we'll save this for another time.)","metadata":{}},{"cell_type":"code","source":"# read files into DF\n\n# initialize a dataframe\ndivvy_trips <- data.frame()\n\n# store colnames in a special DF to verify uniformity\ncolnames_df <- data.frame()\nmetadata_df <- data.frame()\n\nfor (i in 1:length(csv_file_list)){\n\n  temp_data <- read_csv( paste( source_data_dir, csv_file_list[i], sep='/'),\n                         show_col_types = FALSE)\n  \n  # drop columns we will not be needing (longitude, latitude, etc.)\n  # to reduce memory usage\n  temp_data <- temp_data %>%\n    select( -c( start_lat, start_lng, end_lat, end_lng))\n\n\n  # Add a \"ride_duration_sec\" calculation to divvy_trips (in seconds)\n  temp_data$ride_duration_sec <- as.numeric(as.character(difftime( temp_data$ended_at, temp_data$started_at), units = c(\"secs\")))\n\n  \n  # get colnames and add them to a separate dataframe for analysis\n  colnames_df <- rbind( colnames_df, c( csv_file_list[i], ncol(temp_data), colnames(temp_data)))\n\n  # add statistical info about the data in each file to a separate DF\n\n  metadata_df <- rbind( metadata_df,\n      c( csv_file_list[i], nrow(temp_data), NA,\n        list(\n          min(temp_data$started_at),\n          # period in days covered by this CSV\n          as.numeric( as.character( difftime( max(temp_data$started_at),\n            min(temp_data$started_at)), units = c(\"days\")))\n          )\n        )\n  )\n  \n  \n  # add newly ingested data to the dataframe\n  # (for each iteration, bind the new data to the building dataset)\n  divvy_trips <- rbind(divvy_trips, temp_data)\n\n\n}\n\n#\n# colnames(colnames_df) <- c(\"filename\", \"ncols\", colnames(temp_data))\ncolnames(metadata_df) <- c(\"filename\", \"no_rides\", \"% of total rides\",\n    \"date_started_at - first\", \"period in days\")\n\n# calculate percentages of total rides for each CSV\nmetadata_df$'% of total rides' <- sprintf( \"%0.2f%%\", metadata_df$no_rides / sum(metadata_df$no_rides) * 100)\n\n\n# set a datetime column to POSIXct type - if the column name starts with `_date`\ndate_columns <- grep('^date_', names(metadata_df))\nmetadata_df[date_columns] <- lapply(metadata_df[date_columns], function(x) as.POSIXct(x, origin = '1970-01-01'))\n\ncolnames(colnames_df) <- c(\"filename\", \"no. of columns\", colnames(temp_data))\n","metadata":{"execution":{"iopub.status.busy":"2022-01-26T03:00:14.02283Z","iopub.execute_input":"2022-01-26T03:00:14.024801Z","iopub.status.idle":"2022-01-26T03:00:54.830147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Examining the two auxiliary dataframes - `colnames_df` and `metadata_df` created in the above code chunk gives us aggregated information about each CSV and whether it contains good data, and uniform column names. We'll do such rudimentary checking in the next code chunk - yet it's always a good idea to examine those two small dataframes manually via `View()`.","metadata":{}},{"cell_type":"markdown","source":"1.4. Cursory check on the ingested data.","metadata":{}},{"cell_type":"code","source":"# Verify validity and integrity of the ingested data\n\n# analyze the two generated metadata dataframes (colnames_df, metadata_df) for issues:\n# - all columns should be the same except for 'filename' in colnames_df\n# - look for anomalies in metadata_df\n\n# the dataframe contains field names (column names) from each CSV file that is part of the\n# divvy_trips dataframe and for the dataset to be analyzed, fields and their types must match\n\n# - sum the rows in divvy_trips_metadata, compare to # of row in the resulting\n#   dataframe - this should give us an idea if anything went wrong\n# - check for bad types (non-numeric values that should only be numeric, non-dates that should be dates\n# - check for date consistencies - e.g. no multi-day gaps or unusual spikes\n#   indicating potential DQ issues\n\ndatarows_ingested <- \n  summarise( \n    metadata_df,\n    numrows = sum( as.numeric(as.character(no_rides))))$numrows\n\ncat( \"total rows ingested      :\", datarows_ingested, \"\\n\")\ncat( \"rows in the final dataset:\", nrow(divvy_trips), \"\\n\")\ncat( \"difference               :\", datarows_ingested - nrow(divvy_trips), \"\\n\")\ncat( \"all observations counted :\", datarows_ingested == nrow(divvy_trips), \"\\n\")\n\n\n# check for NA values in columns where there shouldn't be any\n\n# percentage of NA vs. all values in the dataframe:\ncat( \"          percent of NAs :\",\n      sprintf( '%0.2f%%', sum(colSums(is.na(divvy_trips))) /\n        (nrow(divvy_trips) * ncol(divvy_trips)) * 100), \" (of all values)\\n\")\n\n# total NAs only in columnns we care about (timestamps, duration, user type)\ndivvy_cols_we_need <- c(\"ride_id\", \"rideable_type\", \"started_at\", \"ended_at\", \"member_casual\", \"ride_duration_sec\")\ncat( \"      NAs in key columns :\", \n      colSums(is.na(divvy_trips[divvy_cols_we_need])) %>% sum(), \"\\n\")\n\n# see NAs across all columns\ncolSums(is.na(divvy_trips)) %>%\n  as.data.frame() %>% \n  `colnames<-`(\"NAs\") %>%\n  View()","metadata":{"execution":{"iopub.status.busy":"2022-01-26T03:00:54.834604Z","iopub.execute_input":"2022-01-26T03:00:54.837095Z","iopub.status.idle":"2022-01-26T03:00:59.190068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Key findings from the above output:\n* All the rows in the CSVs have been successfuly ingested.\n* Checking `colnames_df` and `metadata_df` shows no apparent issues with the data, or inconsistencies in column names.\n* `NA` values in key columns (that we will be analyzing): 0. That's good news.\n* `NA` values in station names and IDs: about 1%. This potentially indicates a data quality issue.\n\nIf this was a real world project, the missing stations may have required us to go back to the source of the data and check on the reasons those stations are missing, and document it before proceeding. Given this is an exercise, we'll simply be mindful of this and proceed regardless.","metadata":{}},{"cell_type":"markdown","source":"### Step 2: Clean and prepare\n\n* identify and remove aberrant data;\n* transform data or convert types if needed  - e.g. `character` timestamps to `POSIXct`, etc. (not needed)\n* calculate needed fields - e.g. duration, \"day of week\", \"year\", etc. (already done for `ride_duration_sec` while other values are calculated on the fly.\n\n\n#### Removing aberrant data\n\nThe \"[Divvy Data](https://ride.divvybikes.com/system-data)\" page says this:\n\n> The data has been processed to remove trips that are taken by staff as they service and inspect the system; and any trips that were below 60 seconds in length (potentially false starts or users trying to re-dock a bike to ensure it was secure).\n\nThis tells us:\n\n1. Removing trips under 60 seconds should be safe.\n1. Identifying and removing maintenance trips (\"taken by staff as they service and inspect the system\") - should also be safe.\n\nAlso: whould we drop trips over a day? (Nobody takes the bikes home or rides long distance - the service is designed for two rider types:\n\n* commute (station to station), and\n* casual / leisure - \"ride in a park or along the bankment\" type where the bikes are usually returned to the same station. (We should run an analysis to confirm the latter.)\n\nYet given no indication the dataset owners are doing that in their [\"cleaned data\"](https://ride.divvybikes.com/system-data) - or that anyone else is doing that, we'll drop that idea for this exercise.)","metadata":{}},{"cell_type":"markdown","source":"* Next: analyze trips under 60 seconds","metadata":{}},{"cell_type":"code","source":"summary(divvy_trips$ride_duration_sec)\n\n# The above tells us the dataset may have a significant number of trips\n# with negative duration. Let's see how many, percentage of total, and\n# perhaps how many unique stations are involved\n\nsprintf( \"%0.2f%%: percentage of trips with negative duration\", length( which( divvy_trips$ride_duration_sec < 0 )) / nrow(divvy_trips) * 100)\n# result  0.05%, or statistically insignificant\n# what about < 60 seconds?\n\nsprintf( \"%0.2f%%: percentage of trips < 60 seconds\", length( which( divvy_trips$ride_duration_sec < 60 )) / nrow(divvy_trips) * 100)\n# 1.57% - which is quite a bit more","metadata":{"execution":{"iopub.status.busy":"2022-01-26T03:00:59.193483Z","iopub.execute_input":"2022-01-26T03:00:59.195855Z","iopub.status.idle":"2022-01-26T03:01:00.154541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This tells us there's clearly some issues with the data - negative and unusually high (over a day) ride durations. Let's analyize this a little more.","metadata":{}},{"cell_type":"markdown","source":"* Next: Analyze distribution of trip durations","metadata":{}},{"cell_type":"code","source":"\ndivvy_trips %>% \n  mutate( ride_duration = case_when(\n    ride_duration_sec < 0 ~ \"segment 1: < 0\",\n    ride_duration_sec < 60 ~ \"segment 2: < 1m\",\n    ride_duration_sec < 60*60 ~ \"segment 3: < 60m\",\n    ride_duration_sec < 60*60*3 ~ \"segment 4: < 3h\",\n    ride_duration_sec < 60*60*24 ~ \"segment 5: < 1d\",\n    ride_duration_sec >= 60*60*24 ~ \"segment 6: >= 1d\",\n    TRUE ~ \"all other\")) %>% \n  \n  group_by( ride_duration) %>% \n\n  summarise(\n    trips = n()\n    ,'percent trips' = sprintf( '%7.2f%%', trips /\n                                 nrow(divvy_trips) * 100)\n    # ,'percent start stations involved' =\n    #   sprintf( '%0.2f%%', length( unique( start_station_id)) /\n    #   length( unique( divvy_trips$start_station_id)) * 100)\n    # ,'percent end stations involved' =\n    #   sprintf( '%0.2f%%', length( unique( end_station_id)) /\n    #   length( unique( divvy_trips$end_station_id)) * 100)\n    # ,'avg duration' = mean( ride_duration_sec)\n  )","metadata":{"execution":{"iopub.status.busy":"2022-01-26T03:01:00.161455Z","iopub.execute_input":"2022-01-26T03:01:00.165987Z","iopub.status.idle":"2022-01-26T03:01:04.066128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The above tells us:\n* Percentage of trips with negative durations is very small.\n* Percentage of trips with unusually long durations (over a day) is also very small.\n* Percentage of trips under a minute is realtively high (1.5%) - and we're supposed to drop them as they are likely \"bike re-docking\", per Divvy Bikes.\n* Despite that the percentage of unusually long trips is small, they may still skew average durations in our analysis, and thus it may be a good idea to drop them. We will analyse this in more details further in our analysis.","metadata":{}},{"cell_type":"markdown","source":"* Next: visualize distribution of aberrant trip durations: negative or over a day","metadata":{}},{"cell_type":"code","source":"# visualize distribution of aberrant trip durations - negative or over a day\n\ndivvy_trips %>% \n  filter( ride_duration_sec < 0 | ride_duration_sec > 60*60*24) %>% \n\n  mutate( year_month = sprintf( '%d-%02d',\n                                year(started_at), month(started_at))) %>% \n\n  mutate( ride_duration_segment = case_when(\n    ride_duration_sec < 0 ~ \" < 0\",\n    ride_duration_sec < 60 ~ \"< 1m\",\n    ride_duration_sec < 60*60 ~ \"< 60m\",\n    ride_duration_sec < 60*60*3 ~ \"< 3h\",\n    ride_duration_sec < 60*60*24 ~ \"< 1d\",\n    ride_duration_sec >= 60*60*24 ~ \">= 1d\",\n    TRUE ~ \"all other\")) %>% \n  \n  group_by( ride_duration_segment, year_month) %>% \n\n  summarise(\n    tripsK = n() / 1000\n    # ,'percent trips' = sprintf( '%0.2f%%', tripsK /\n    #                              nrow(divvy_trips) * 100)\n  ) %>%\n  \n  arrange( ride_duration_segment, year_month)  %>%\n  \n  ggplot( aes( x = year_month, y = tripsK, fill = ride_duration_segment)) +\n    labs( x = \"date\",\n        y = \"number of rides (thousands)\",\n        fill = \"ride duration\") +\n    labs( title   = \"Trip Durations\",\n          caption = sprintf( \n            \"Data: Divvy Bikes (City of Chicago). Dates: from %s to %s.\",\n            format( min( divvy_trips$started_at), \"%D\"),\n            format( max( divvy_trips$started_at), \"%D\")\n            )\n          ) +\n    theme(axis.text.x = element_text(angle = 60, vjust = 1.0, hjust=1)) +\n    geom_col( position = \"dodge\")","metadata":{"execution":{"iopub.status.busy":"2022-01-26T03:01:04.069012Z","iopub.execute_input":"2022-01-26T03:01:04.070743Z","iopub.status.idle":"2022-01-26T03:01:04.631454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The viz above tells us there's an unusually high number of trips with negative durations in 2020. Trips over a day are more evenly spread. While neither trip type is statistically significant (under a percent each), either one is likely aberrant, or not a legitimate trip type:\n\n* either the bike was not docked properly (in case of durations over a day),\n* or the data was not recorded correctly (when the duration is negative)\n\nIn either case presence of large negative or positive duration values may skew statistical calculations and either type should probably be excluded.","metadata":{}},{"cell_type":"markdown","source":"* Next: check rider types to ensure no abberant values and percent of total trips by each type","metadata":{}},{"cell_type":"code","source":"# table(divvy_trips$member_casual)\n\ndivvy_trips %>% \n  group_by( member_casual) %>% \n  summarise(\n    count = n(),\n    percent = sprintf( '%0.2f%%', count / nrow( divvy_trips) * 100)\n  )\n\n# if there are aberrant / unexpected values, we'd need to use mutate / recode\n# to convert them for further analysis","metadata":{"execution":{"iopub.status.busy":"2022-01-26T03:01:04.63521Z","iopub.execute_input":"2022-01-26T03:01:04.637511Z","iopub.status.idle":"2022-01-26T03:01:04.839849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"No apparent issues with the data above.","metadata":{}},{"cell_type":"markdown","source":"* Next: checking `rideable_type` values for anything unusual","metadata":{}},{"cell_type":"code","source":"divvy_trips %>% \n  group_by( rideable_type) %>% \n  summarise(\n    count = n(),\n    percent = sprintf( '%0.2f%%', count / nrow( divvy_trips) * 100)\n  )","metadata":{"execution":{"iopub.status.busy":"2022-01-26T03:01:04.843666Z","iopub.execute_input":"2022-01-26T03:01:04.845906Z","iopub.status.idle":"2022-01-26T03:01:05.040248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The above tells us there's a significant number (8.63% for this dataset) of trips with \"docked_bike\" in the `rideable_type` field. We don't know what a \"docked_bike\" is and why there are trips with it. E.g. a \"docked_boat\" (in real life) normally doesn't float anywhere and if it does - call the police. Attempting to Google this or ask the dataset owner - no dice. Yet given the question we need to answer:\n\n> How do annual members and casual riders use Cyclistic bikes differently?\n\n... we shall not engage with this \"docked_bike\" mystery for now.","metadata":{}},{"cell_type":"markdown","source":"* Next: attempting to ID \"maintenance\" trips - made to/from \"maintenance\" stations","metadata":{}},{"cell_type":"code","source":"# attempting to ID \"maintenance\" trips - those made to/from \"maintenance\" stations\n# they could be \"HQ QR\", stations containing \"test\" or \"divvy\" in the name\n\ndivvy_trips %>% \n  filter( \n    grepl( 'test|repair', start_station_name, ignore.case = TRUE) |\n      grepl( 'test|repair', end_station_name, ignore.case = TRUE)\n    ) %>% \n  group_by( start_station_name, end_station_name) %>% \n  summarise(\n    trips = n(),\n    'avg duration (minutes)' = sprintf( '%0.2f', mean( ride_duration_sec) / 60)\n  ) %>% \n  arrange( desc(trips))\n\n\n# this identifies a number of trips to/from stations that look like\n# maintenance stations, where these trips should perhaps be ignored","metadata":{"execution":{"iopub.status.busy":"2022-01-26T03:01:05.044352Z","iopub.execute_input":"2022-01-26T03:01:05.047052Z","iopub.status.idle":"2022-01-26T03:01:11.884117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The above tells us that most of the trips found through this search are very low in duration and unlikely to be real trips made by customers - in addition to them being to/from a \"testing\" station. We shall exclude them going forward.","metadata":{}},{"cell_type":"markdown","source":"* Next: Removing \"testing\" and \"repair\" trips, and those under 60 seconds.","metadata":{}},{"cell_type":"code","source":"# drop rows with duration < 60 seconds and to/from test stations\n\ndivvy_trips <- divvy_trips %>% \n  filter(\n    ride_duration_sec >= 60 &\n    !(grepl( 'test|repair', start_station_name, ignore.case = TRUE) |\n      grepl( 'test|repair', end_station_name, ignore.case = TRUE))\n    )\n","metadata":{"execution":{"iopub.status.busy":"2022-01-26T03:01:11.886673Z","iopub.execute_input":"2022-01-26T03:01:11.888121Z","iopub.status.idle":"2022-01-26T03:01:18.961581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Next: data quality check: distribution of trips over months","metadata":{}},{"cell_type":"code","source":"# confirm we're not missing any months\n\ndivvy_trips %>% \n  \n  # mutate( 'day of week' = wday(started_at, label = TRUE)) %>% \n  # mutate( year = year(started_at)) %>% \n  # mutate( month = month(started_at)) %>% \n  mutate( year_month = sprintf( '%d-%02d', year(started_at), month(started_at))) %>% \n  group_by( year_month) %>%\n  summarise(\n    trips = n(),\n    'percent of all trips' = sprintf( '%0.2f%%', trips / nrow( divvy_trips) * 100),\n    'avg duration (minutes)' = sprintf( '%0.2f', mean( ride_duration_sec) / 60),\n    'percent total duration' =\n      sprintf( '%0.2f%%', sum( ride_duration_sec) / sum( divvy_trips$ride_duration_sec) * 100)\n  ) %>% View()","metadata":{"execution":{"iopub.status.busy":"2022-01-26T03:01:18.965612Z","iopub.execute_input":"2022-01-26T03:01:18.968203Z","iopub.status.idle":"2022-01-26T03:01:24.988991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The above tells us that there's not a month w/o data - i.e. nothing is obviosly missing - yet let's visualize this:","metadata":{}},{"cell_type":"code","source":"divvy_trips %>% \n  \n  # mutate( 'day of week' = wday(started_at, label = TRUE)) %>% \n  # mutate( year = year(started_at)) %>% \n  # mutate( month = month(started_at)) %>% \n  mutate( year_month = sprintf( '%d-%02d', year(started_at), month(started_at))) %>% \n  group_by( year_month) %>%\n  summarise( trips = n()) %>%\n\n  arrange( trips, year_month) %>% \n  \n  ggplot( aes( x = year_month, y = trips)) +\n  labs( x = \"month\",\n        y = \"trips\") +\n  labs( title   = \"Number of trips over time\",\n        caption = sprintf( \n          \"Data: Divvy Bikes (City of Chicago). Dates: from %s to %s.\",\n          format( min( divvy_trips$started_at), \"%D\"),\n          format( max( divvy_trips$started_at), \"%D\")\n          )\n        ) +\n\n  geom_col( position = \"dodge\")","metadata":{"execution":{"iopub.status.busy":"2022-01-26T03:01:24.99294Z","iopub.execute_input":"2022-01-26T03:01:24.995386Z","iopub.status.idle":"2022-01-26T03:01:30.499612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The above bar graph shows the expected distribution of trips (rides) across a year, with rides sharply down in the winter, and picking up in the summer.","metadata":{}},{"cell_type":"markdown","source":"#### Conclusions for Step 3 (cleaning and preparation)\n\nThere is a number of issues with the data and its collection:\n\n* A significant number of trips under a minute in duration. Those between 0 and 60 seconds likely indicate inadvertent or deliberate \"redocking\" to make sure the bike is marked as \"returned\" in the system. Yet those with negative duration (under a percent) indicate simply bad data.\n* A significant number of trips with `NA` (about a percent) for a starting and/or ending station.\n* A number of trips with durations over a day - very unlikely to be legitimate trips.\n* A sigificant number of trips where `rideable_type` aka \"bicycle type\" is `docked_bike` - which we know nothing about (unlike `classic_bike` and `electric_bike`) and which doesn't seem to be mentioned anywhere in the documentation.\n* There are *three* options for riders: single ride, [day pass](https://ride.divvybikes.com/pricing/24-hour-pass/kiosk-instructions) (aka [\"Explorer Pass\"](https://chi.streetsblog.org/2018/01/24/divvy-finally-introduces-3-single-ride-option-45-minute-time-limit-for-members/), and annual pass (aka \"members\") - yet only two corresponding values in the dataset (\"casual\" and \"member\"). The same is true for the [\"cleaned data\"](https://ride.divvybikes.com/system-data) (2013-2019). It is likely that single rides and day passes are bundled together into \"casual\" in the dataset - yet regardless, this means some of the data that is key to our business task (\"How do annual members and casual riders use bikes differently?\") may be missing.\n\nAt this point, we can't be sure we can trust the data - only *assume* some of it may be OK. The best course of action from here is to engage with the dataset owner to get more information on how the data was collected, and how to remove bad data. Yet for this exercise (a capstone project done by thousands of aspiring data analysts) - would it make sense to bug dataset owners? Probably not. I tried anyway: no response.\n\nTo sum up: **does the data [\"ROCCC\"](https://www.coursera.org/lecture/data-preparation/what-is-bad-data-lHirM)**?\n\n* Is it **R**eliable? Can't be sure - further analysis is needed to understand where the bad data comes from and how to deal with it.\n* Is it **O**riginal? **Yes**: comes directly from the service collecting the data, per dataset owners.\n* **C**omprehensive? **Not entirely** given there's *missing* data: a number of `NA` values for starting and ending stattions in the dataset.\n* **C**urrent? **Yes** for a specific timeframe - i.e. not outdated for the purpose of this analysis.\n* **C**ited: **unclear**: I have not found that the dataset owners or any 3rd party are vouching for the accuracy of their data - i.e. citing it. Rather, we see that they **had to clean their own data** in order to present it on their web site - without providing clear instructions, how.\n\n**Conclusion** (for cleaning and preparing steps): the data does not [\"ROCCC\"](https://www.coursera.org/lecture/data-preparation/what-is-bad-data-lHirM) (is not fully reliable) - yet **this is only an exercise**, not a real world project. We can thus ignore the data quality issues and proceed as if it is reliable.","metadata":{}},{"cell_type":"markdown","source":"### Step 4: Analysis and Visualizations\n(i.e. identify trends and insights answering the \"business task\" at hand)","metadata":{}},{"cell_type":"markdown","source":"* Next: visualize average duration by user type over time","metadata":{}},{"cell_type":"code","source":"divvy_trips %>% \n  # head(1000*1000) %>%\n  mutate( year_month = sprintf( '%d-%02d',\n                                year(started_at), month(started_at))) %>% \n\n  group_by( member_casual, year_month) %>% \n  \n  summarise( number_of_rides = n(),\n             avg_duration = mean(ride_duration_sec) / 60) %>% \n  arrange( member_casual, year_month)  %>% \n  \n  ggplot( aes( x = year_month, y = avg_duration, fill = member_casual)) +\n    labs( x = \"date\",\n        y = \"average duration (minutes)\",\n        fill = \"rider type\") +\n    labs( title   = \"Average duration by rider type\",\n          caption = sprintf( \n            \"Data: Divvy Bikes (City of Chicago). Dates: from %s to %s.\",\n            format( min( divvy_trips$started_at), \"%D\"),\n            format( max( divvy_trips$started_at), \"%D\")\n            )\n          ) +\n    theme(axis.text.x = element_text(angle = 60, vjust = 1.0, hjust=1)) +\n    geom_col( position = \"dodge\")","metadata":{"execution":{"iopub.status.busy":"2022-01-26T03:01:30.503608Z","iopub.execute_input":"2022-01-26T03:01:30.506149Z","iopub.status.idle":"2022-01-26T03:01:36.402224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The above viz shows unusual, unexpected spike in trip duration for both casual riders and members in January 2021. Members' duration go back to baseline values while casual riders - stay higher until August.\n\nCould this indicate a data quality issue, possibly to do with bikes that haven't been properly docked and thus result in aberrant multi-day \"rides\"? Let's explore in the next code chunk.","metadata":{}},{"cell_type":"markdown","source":"* Next: same viz as above - except drop trips over a day (which may skew average durations significantly even if there are very few of them).","metadata":{}},{"cell_type":"code","source":"# same viz as in the previous code chunk - except drop trips over a day\n\ndivvy_trips %>% \n  # head(1000*1000) %>%\n  filter( ride_duration_sec <= 60*60*24) %>% \n  mutate( year_month = sprintf( '%d-%02d',\n                                year(started_at), month(started_at))) %>% \n\n  group_by( member_casual, year_month) %>% \n  \n  summarise( number_of_rides = n(),\n             avg_duration = mean(ride_duration_sec) / 60) %>% \n  arrange( member_casual, year_month)  %>% \n  \n  ggplot( aes( x = year_month, y = avg_duration, fill = member_casual)) +\n    labs( x = \"date\",\n        y = \"average duration (minutes)\",\n        fill = \"rider type\") +\n    labs( title   = \"Average duration by rider type (trips under 1 day in duration)\",\n          caption = sprintf( \n            \"Data: Divvy Bikes (City of Chicago). Dates: from %s to %s.\",\n            format( min( divvy_trips$started_at), \"%D\"),\n            format( max( divvy_trips$started_at), \"%D\")\n            )\n          ) +\n    theme(axis.text.x = element_text(angle = 60, vjust = 1.0, hjust=1)) +\n    geom_col( position = \"dodge\")","metadata":{"execution":{"iopub.status.busy":"2022-01-26T03:01:36.404842Z","iopub.execute_input":"2022-01-26T03:01:36.406459Z","iopub.status.idle":"2022-01-26T03:01:43.765272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The graph is quite a bit different!\n\n* average durations dropped significantly for casual riders - from the high of 50 minutes - to around 30\n* there is still a spike for \"members\" in January - although it's a smaller one\n\n**Conclusion**: we should drop trips over a day as likely aberrant, when analyzing trip durations - or find a way to vet (cite) the data to ensure its accuracy.","metadata":{}},{"cell_type":"markdown","source":"* User type stats over \"day of the week\"","metadata":{}},{"cell_type":"code","source":"divvy_trips %>% \n  mutate( trip_type = case_when(\n    start_station_id == end_station_id ~ \"same to/from station\",\n    TRUE ~ \"different to/from stations\")) %>% \n  mutate( 'day of week' = wday(started_at, label = TRUE)) %>% \n  # group_by( trip_type, member_casual) %>% \n  # group_by( trip_type, rideable_type) %>%\n  # group_by( rideable_type) %>%\n  # group_by( trip_type) %>%\n  # group_by( `day of week`) %>%\n  group_by( `day of week`, member_casual) %>%\n  summarise(\n    trips = n(),\n    'percent of all trips' = sprintf( '%0.2f%%', trips / nrow( divvy_trips) * 100),\n    'avg duration (minutes)' = sprintf( '%0.2f', mean( ride_duration_sec) / 60),\n    'percent total duration' =\n      sprintf( '%0.2f%%', sum( ride_duration_sec) /\n                 sum( divvy_trips$ride_duration_sec) * 100)\n  )","metadata":{"execution":{"iopub.status.busy":"2022-01-26T03:01:43.767985Z","iopub.execute_input":"2022-01-26T03:01:43.769707Z","iopub.status.idle":"2022-01-26T03:01:51.17787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The table above is rather hard to read so let's visualize it","metadata":{}},{"cell_type":"markdown","source":"* Visualize number of rides by rider type, by day of the week","metadata":{}},{"cell_type":"code","source":"# Let's visualize the number of rides by rider type\ndivvy_trips %>% \n  # head(100000) %>%\n  within( weekday <- wday( started_at, label = TRUE)) %>%\n\n  group_by( member_casual, weekday) %>%\n  \n  summarise( 'number of rides' = n() / 1000,\n    'avg duration' = mean( ride_duration_sec)\n    ) %>%\n  arrange( member_casual, weekday) %>% \n\n  \n  ggplot( aes( x = weekday, y = `number of rides`, fill = member_casual)) +\n  labs( x = \"day of the week\",\n        y = \"number of rides (thousands)\",\n        fill = \"rider type\") +\n  labs( title   = \"Number of rides by rider type\",\n        caption = sprintf( \n          \"Data: Divvy Bikes (City of Chicago). Dates: from %s to %s.\",\n          format( min( divvy_trips$started_at), \"%D\"),\n          format( max( divvy_trips$started_at), \"%D\")\n          )\n        ) +\n\n  geom_col( position = \"dodge\")","metadata":{"execution":{"iopub.status.busy":"2022-01-26T03:01:51.180445Z","iopub.execute_input":"2022-01-26T03:01:51.181821Z","iopub.status.idle":"2022-01-26T03:01:58.239019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* calculate *trips per day* on weekends / weekday and the difference between them","metadata":{}},{"cell_type":"code","source":"# weekend trips vs. weekday trips - aggregated\n# (this is probably very bad, inefficient R - but I am still learning!)\n\ndivvy_trips %>% \n  mutate( 'day of week' = wday(started_at, label = TRUE)) %>% \n  mutate( weekend = case_when(\n    `day of week` %in% c('Sat', 'Sun') ~ TRUE,\n    TRUE ~ FALSE)\n  ) %>% \n  group_by( member_casual, weekend) %>%\n  summarise(\n    trips = n(),\n    'percent of all trips' = sprintf( '%0.2f%%', trips / nrow( divvy_trips) * 100),\n    'avg duration (minutes)' = sprintf( '%0.2f', mean( ride_duration_sec) / 60),\n    'percent total duration' =\n      sprintf( '%0.2f%%', sum( ride_duration_sec) /\n                 sum( divvy_trips$ride_duration_sec) * 100)\n  ) %>%\n  mutate( 'trips per day' = case_when(\n    weekend ~ trips / 2,\n    TRUE ~ trips / 5)\n  ) %>% \n  # mutate( trip_sum = sum(`trips per day`)) %>% \n  mutate( 'percent per day per rider type' = sprintf(\n    '%0.2f%%', `trips per day` / sum(`trips per day`)  * 100))","metadata":{"execution":{"iopub.status.busy":"2022-01-26T03:01:58.241577Z","iopub.execute_input":"2022-01-26T03:01:58.24307Z","iopub.status.idle":"2022-01-26T03:02:05.041727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The above tells us that \"casual\" riders take more trips *per day* (78% more) on the weekend (Saturdays and Sundays), and fewer - during the weekdays, with an uptick on Fridays. However \"member\" (annual pass) usage does not fall off on the weekends (per day) - i.e. their trips aren't just about commuting to/from work, apparently. In other words, this visualizations tells us:\n\n**Casual riders take more trips per day on the weekends** compared to weekdays.\n\nPerhaps we could recommend to Divvy Bikes that they explore special \"weekends only\" annual passes that could be attractive enough to casual weekend riders to invest in them. We'd then need to analyze metrics such average annual spending of casual riders - perhaps something we could put forward as a recommendation.","metadata":{}},{"cell_type":"markdown","source":"* Next: visualization for **average duration** by rider type / day of week","metadata":{}},{"cell_type":"code","source":"# visualize average duration by rider type by day of week\n\ndivvy_trips %>% \n  # head(100000) %>%\n  within( weekday <- wday(started_at, label = TRUE)) %>%\n  group_by( member_casual, weekday) %>% \n\n  summarise( number_of_rides = n(),\n             avg_duration = mean(ride_duration_sec) / 60) %>% \n  arrange( member_casual, weekday)  %>% \n\n  ggplot( aes( x = weekday, y = avg_duration, fill = member_casual)) +\n  labs( x = \"day of the week\",\n        y = \"average duration (minutes)\",\n        fill = \"rider type\") +\n  labs( title   = \"Average duration by rider type by day of the week\",\n        caption = sprintf( \n          \"Data: Divvy Bikes (City of Chicago). Dates: from %s to %s.\",\n          format( min( divvy_trips$started_at), \"%D\"),\n          format( max( divvy_trips$started_at), \"%D\")\n          )\n        ) +\n\n    geom_col( position = \"dodge\")","metadata":{"execution":{"iopub.status.busy":"2022-01-26T03:02:05.045587Z","iopub.execute_input":"2022-01-26T03:02:05.048121Z","iopub.status.idle":"2022-01-26T03:02:11.20813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* average duration by rider type for weekends and weekdays","metadata":{}},{"cell_type":"code","source":"divvy_trips %>% \n  # head(100000) %>%\n  mutate( 'day of week' = wday(started_at, label = TRUE)) %>% \n  mutate( weekend = case_when(\n    `day of week` %in% c('Sat', 'Sun') ~ TRUE,\n    TRUE ~ FALSE)\n  ) %>% \n\n  group_by( member_casual, weekend) %>% \n\n  summarise( trips = n(),\n             'avg duration minutes' = mean(ride_duration_sec) / 60)","metadata":{"execution":{"iopub.status.busy":"2022-01-26T03:14:06.034226Z","iopub.execute_input":"2022-01-26T03:14:06.037459Z","iopub.status.idle":"2022-01-26T03:14:12.649824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Average duration goes up 23% for casual riders on the weekends (30 to 37 minutes), and 18% (from 13.5 to 16 minutes) for members.\n\nThe key takeaway:\n\n**Casual riders take longer trips** - over twice as long on average.\n\nIn other words, there may be a point to promote special weekend-only annual passes to casual weekend riders by offering longer rides compared to standard members.","metadata":{}},{"cell_type":"markdown","source":"### Step 4: Summary, Conclusions, Recommendations\n\nTo answer the key question we've been tasked to answer:\n\n> How do annual members and casual riders use Cyclistic bikes differently?\n\n* **Casual riders take more trips on the weekends** (Saturdays and Sunday) - about 50% more, compared to weekdays. There's also a marked increase in the number of trips on Fridays for casual riders - about 20% higher vs. other weekdays.\n* **Casual riders take longer trips** - about 30 minutes on average compared to 15 minutes for \"members\".\n* They (casual riders) don't take significantly longer trips on the weekends - i.e. the duration of their rides doesn't change from weekdays to weekends.\n\n#### Conclusions\n\n* Casual riders take significantly more trips on the weekends (Saturdays and Sundays), and also on Fridays. They also generally take longer rides compared to members - about twice as long.\n* Members' (annual pass holders) do not vary as significantly in the number of trips taken on the weekends vs. weekdays.\n* Further analysis is needed to determine the exact recommendations as well as address potential data quality issues.\n\n#### Recommendations\n\n* Given that casual riders generally take longer rides, and take significantly more rides (trips) between Friday and Sunday, explore offering special **weekends-only annual passes** targeting casual riders that would allow them to take unlimited trips during the weekend for a flat annual fee, similar to annual pass holders, but with a longer duration limit vs. \"members\".\n    + Side note: Divvy Bikes does offer *day passes* that somewhat address the above recommendation. Yet we can't analyse day pass usage separately as there are't \"day pass\" rides in the dataset - possibly because day pass holders are bundled together with single-trip riders into the \"casual\" category.\n* Explore **pricing (profitability and ROI) analysis** for higher quality recommendations. E.g. if we could determine that some casual riders spends more than members during certain months or per year, we could potentially entice them with annual passes tailored to their usage pattern. (This would require to track individual riders while anonymizing their data to gauge their pattern of usage throughout the year - something this dataset doesn't offer. I.e. there's no way currently to determine usage patterns or average spending per rider (casual or member) per year or per month - as there are no rider IDs allowing to attribute trips to a specific rider.)\n* Discuss data quality issues documented above with dataset owners to ensure the data is reliable.\n* Ask what the `docked_bike` means for `rideable_type` - which accounts for about 8% of total trips.","metadata":{}}]}